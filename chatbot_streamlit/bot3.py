import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import json
from pathlib import Path

# Carrega variÃ¡veis do .env
load_dotenv()

# Para rodar o sistema: streamlit run bot.py

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNÃ‡ÃƒO PARA CARREGAR PROMPTS DE ARQUIVOS EXTERNOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data
def carregar_prompt_do_arquivo(caminho_arquivo="prompt.txt"):
    """
    Carrega o prompt do sistema de um arquivo externo
    Cria o arquivo com prompt padrÃ£o se nÃ£o existir
    """
    try:
        # Cria diretÃ³rio se nÃ£o existir
        Path(caminho_arquivo).parent.mkdir(parents=True, exist_ok=True)
        
        # Se arquivo nÃ£o existir, cria com prompt padrÃ£o
        if not os.path.exists(caminho_arquivo):
            prompt_padrao = """VocÃª Ã© um assistente de suporte tÃ©cnico especializado em desenvolvimento de software, Python e Streamlit.

CaracterÃ­sticas:
- Responda de forma clara, objetiva e profissional
- ForneÃ§a soluÃ§Ãµes prÃ¡ticas e cÃ³digo quando apropriado  
- Seja prestativo e paciente
- Use exemplos quando necessÃ¡rio
- Mantenha um tom amigÃ¡vel mas tÃ©cnico

InstruÃ§Ãµes especÃ­ficas:
- Sempre teste suas sugestÃµes de cÃ³digo
- Explique o "porquÃª" das suas recomendaÃ§Ãµes
- Se nÃ£o souber algo, admita e sugira onde buscar
- Priorize boas prÃ¡ticas de desenvolvimento"""
            
            with open(caminho_arquivo, 'w', encoding='utf-8') as f:
                f.write(prompt_padrao)
            st.info(f"ğŸ“„ Arquivo de prompt criado em: {caminho_arquivo}")
        
        # LÃª o conteÃºdo do arquivo
        with open(caminho_arquivo, 'r', encoding='utf-8') as f:
            prompt = f.read().strip()
            
        return prompt
        
    except Exception as e:
        st.error(f"âŒ Erro ao carregar prompt: {str(e)}")
        # Retorna prompt bÃ¡sico como fallback
        return "VocÃª Ã© um assistente de suporte tÃ©cnico. Responda de forma clara e objetiva."

@st.cache_data
def carregar_configuracao_json(caminho_arquivo="config/bot_config.json"):
    """
    Carrega configuraÃ§Ãµes do bot de um arquivo JSON
    """
    try:
        Path(caminho_arquivo).parent.mkdir(parents=True, exist_ok=True)
        
        if not os.path.exists(caminho_arquivo):
            config_padrao = {
                "temperatura_padrao": 0.2,
                "max_tokens_padrao": 400,
                "modelo_padrao": "gpt-5-nano",
                "prompts_disponiveis": {
                    "suporte_tecnico": "prompts/prompt_suporte.txt",
                    "assistente_comercial": "prompts/prompt_comercial.txt",
                    "mentor_codigo": "prompts/prompt_mentor.txt"
                }
            }
            
            with open(caminho_arquivo, 'w', encoding='utf-8') as f:
                json.dump(config_padrao, f, indent=2, ensure_ascii=False)
            st.info(f"âš™ï¸ Arquivo de configuraÃ§Ã£o criado em: {caminho_arquivo}")
        
        with open(caminho_arquivo, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        return config
        
    except Exception as e:
        st.error(f"âŒ Erro ao carregar configuraÃ§Ã£o: {str(e)}")
        return {"temperatura_padrao": 0.2, "max_tokens_padrao": 400, "modelo_padrao": "gpt-4o"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAÃ‡ÃƒO E CONFIGURAÃ‡ÃƒO INICIAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Valida a API key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEY nÃ£o encontrada. Crie um arquivo .env com OPENAI_API_KEY=suachave")
    st.stop()

# Instancia o cliente
client = OpenAI(api_key=OPENAI_API_KEY)

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ChatBot IA - Suporte",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Carrega configuraÃ§Ãµes e prompts
config = carregar_configuracao_json()
prompt_sistema_arquivo = carregar_prompt_do_arquivo()

# TÃ­tulo principal
st.write("## ğŸ¤– ChatBot com IA - Suporte TÃ©cnico")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIDEBAR - CONFIGURAÃ‡Ã•ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.sidebar.write("### âš™ï¸ ConfiguraÃ§Ãµes do Bot")

# Seletor de tipo de prompt
tipo_prompt = st.sidebar.selectbox(
    "ğŸ­ Tipo de Assistente:",
    ["Arquivo Personalizado", "Suporte TÃ©cnico", "Comercial", "Mentor de CÃ³digo"],
    help="Escolha o comportamento do assistente"
)

# Carrega prompt baseado na seleÃ§Ã£o
if tipo_prompt == "Arquivo Personalizado":
    prompt_sistema = prompt_sistema_arquivo
    st.sidebar.info("ğŸ“„ Usando prompt de: prompts/prompt_sistema.txt")
elif tipo_prompt == "Suporte TÃ©cnico":
    prompt_sistema = carregar_prompt_do_arquivo("prompts/prompt_suporte.txt")
elif tipo_prompt == "Comercial":
    prompt_sistema = carregar_prompt_do_arquivo("prompts/prompt_comercial.txt")
elif tipo_prompt == "Mentor de CÃ³digo":
    prompt_sistema = carregar_prompt_do_arquivo("prompts/prompt_mentor.txt")

# OpÃ§Ã£o para editar prompt inline (sobrescreve arquivo)
editar_prompt = st.sidebar.checkbox("âœï¸ Editar Prompt", help="Permite editar o prompt atual")

if editar_prompt:
    prompt_editado = st.sidebar.text_area(
        "ğŸ“ Prompt do Sistema (editÃ¡vel):",
        value=prompt_sistema,
        height=200,
        help="Suas alteraÃ§Ãµes serÃ£o salvas no arquivo"
    )
    
    if st.sidebar.button("ğŸ’¾ Salvar no Arquivo"):
        try:
            arquivo_atual = "prompts/prompt_sistema.txt"
            if tipo_prompt == "Suporte TÃ©cnico":
                arquivo_atual = "prompts/prompt_suporte.txt"
            elif tipo_prompt == "Comercial":
                arquivo_atual = "prompts/prompt_comercial.txt"
            elif tipo_prompt == "Mentor de CÃ³digo":
                arquivo_atual = "prompts/prompt_mentor.txt"
                
            with open(arquivo_atual, 'w', encoding='utf-8') as f:
                f.write(prompt_editado)
            
            st.sidebar.success("âœ… Prompt salvo no arquivo!")
            # Limpa cache para recarregar
            st.cache_data.clear()
            st.rerun()
            
        except Exception as e:
            st.sidebar.error(f"âŒ Erro ao salvar: {str(e)}")
    
    prompt_sistema = prompt_editado

# ParÃ¢metros do modelo (usando valores do config)
st.sidebar.write("### ğŸ›ï¸ ParÃ¢metros do Modelo")

temperatura = st.sidebar.slider(
    "ğŸŒ¡ï¸ Temperatura:",
    0.0, 1.0, 
    config.get("temperatura_padrao", 0.2), 
    0.1
)

max_tokens = st.sidebar.number_input(
    "ğŸ“Š MÃ¡ximo de Tokens:",
    50, 1000, 
    config.get("max_tokens_padrao", 400), 
    50
)

modelo = st.sidebar.selectbox(
    "ğŸ§  Modelo:",
    ["gpt-4o-mini","gpt-4.1-nano", "gpt-4o", "gpt-3.5-turbo"],
    index=0 if config.get("modelo_padrao") == "gpt-4o" else 0
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AÃ‡Ã•ES DA SIDEBAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.sidebar.write("### ğŸ› ï¸ AÃ§Ãµes")

col1, col2 = st.sidebar.columns(2)
with col1:
    if st.button("ğŸ—‘ï¸ Limpar", use_container_width=True):
        st.session_state["lista_mensagens"] = []
        st.rerun()

with col2:
    if st.button("ğŸ”„ Recarregar", use_container_width=True):
        st.cache_data.clear()  # Limpa cache dos arquivos
        st.rerun()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INFORMAÃ‡Ã•ES E STATUS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.sidebar.write("---")
st.sidebar.write("### ğŸ“Š Status")

# Inicializa mensagens
if "lista_mensagens" not in st.session_state:
    st.session_state["lista_mensagens"] = []

total_mensagens = len(st.session_state["lista_mensagens"])
st.sidebar.metric("ğŸ’¬ Mensagens", total_mensagens)

# Mostra arquivo sendo usado
st.sidebar.write("### ğŸ“ Arquivos")
st.sidebar.caption("ğŸ“„ Prompt: prompts/prompt_sistema.txt")
st.sidebar.caption("âš™ï¸ Config: config/bot_config.json")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNÃ‡ÃƒO PARA INCLUIR SYSTEM MESSAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def obter_mensagens_completas():
    """Inclui o system message no inÃ­cio da lista de mensagens"""
    system_msg = {"role": "system", "content": prompt_sistema.strip()}
    return [system_msg] + st.session_state["lista_mensagens"]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERFACE PRINCIPAL DO CHAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Exibe histÃ³rico
for msg in st.session_state["lista_mensagens"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant").write(msg["content"])

# Entrada do usuÃ¡rio
mensagem_usuario = st.chat_input("ğŸ’­ Escreva sua mensagem aqui...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCESSAMENTO DA MENSAGEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if mensagem_usuario:
    # Adiciona mensagem do usuÃ¡rio
    st.session_state["lista_mensagens"].append({
        "role": "user", 
        "content": mensagem_usuario
    })
    
    # Exibe mensagem do usuÃ¡rio
    st.chat_message("user").write(mensagem_usuario)
    
    # Processa resposta da IA
    with st.chat_message("assistant"): #, avatar="ğŸ¤–"):
        with st.spinner("ğŸ¤” Pensando..."):
            try:
                resposta = client.chat.completions.create(
                    model=modelo,
                    messages=obter_mensagens_completas(),
                    temperature=temperatura,
                    max_tokens=max_tokens,
                    top_p=0.9,
                    frequency_penalty=0.1
                )
                
                resposta_ia = resposta.choices[0].message.content
                st.write(resposta_ia)
                
                # Adiciona ao histÃ³rico
                st.session_state["lista_mensagens"].append({
                    "role": "assistant", 
                    "content": resposta_ia
                })
                
            except Exception as e:
                st.error(f"âŒ Erro na API: {str(e)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RODAPÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#if total_mensagens == 0:
#    st.info(f"ğŸ‘‹ OlÃ¡! {tipo_prompt} ativo. Como posso ajudÃ¡-lo?")

#st.write("---")
#st.caption("ğŸ“ Prompts carregados de arquivos externos â€¢ ğŸ”§ Configure na barra lateral")